dataset = as.data.frame(as.matrix(dtm))
dataset$Liked = dataset_original$Liked
# Codificar la variable de clasificación como factor
dataset$Liked = factor(dataset$Liked, levels = c(0,1))
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
library(caTools)
set.seed(123)
split = sample.split(dataset$Liked, SplitRatio = 0.80)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Natural Language Processing
setwd("~/repos/machinelearning-az/datasets/Part 7 - Natural Language Processing")
# Importar el dataset
dataset_original = read.delim('data/Restaurant_Reviews.tsv', quote = '',
stringsAsFactors = FALSE)
# Limpieza de textos
library(tm) # Instalar con install.packages('tm')
library(SnowballC) # Instalar con install.packages('SnowballC')
corpus = VCorpus(VectorSource(dataset_original$Review))
corpus = tm_map(corpus, content_transformer(tolower)) # Convertir a minuscula
# Consultar el primer elemento del corpus
#as.character(corpus[[1]])
corpus = tm_map(corpus, removeNumbers) # Eliminar numeros de las reviews del corpus
corpus = tm_map(corpus, removePunctuation) # Eliminar signos de puntuacion
corpus = tm_map(corpus, removeWords, stopwords(kind = 'en')) # Eliminar palabras irrelevantes
corpus = tm_map(corpus, stemDocument) # Eliminar las "variantes" de palabras por su "raiz" ej: loved -> love
corpus = tm_map(corpus, stripWhitespace) # Eliminar espacios en blanco
# Crear el modelo Bag of Words
dtm = DocumentTermMatrix(corpus)
dtm = removeSparseTerms(dtm, 0.999)
dataset = as.data.frame(as.matrix(dtm))
dataset$Liked = dataset_original$Liked
# Codificar la variable de clasificacion como factor
dataset$Purchased = factor(dataset$Liked, levels = c(0, 1))
# Dividir los datos en conjunto de entrenamiento y conjunto de test
library(caTools) # Instalar con install.packages('caTools')
set.seed(123) # Para que salgan los mismos resultados que en el curso
split = sample.split(dataset$Liked, SplitRatio = 0.80)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Natural Language Processing
setwd("~/repos/machinelearning-az/datasets/Part 7 - Natural Language Processing")
# Importar el dataset
dataset_original = read.delim('data/Restaurant_Reviews.tsv', quote = '',
stringsAsFactors = FALSE)
# Limpieza de textos
library(tm) # Instalar con install.packages('tm')
library(SnowballC) # Instalar con install.packages('SnowballC')
corpus = VCorpus(VectorSource(dataset_original$Review))
corpus = tm_map(corpus, content_transformer(tolower)) # Convertir a minuscula
# Consultar el primer elemento del corpus
#as.character(corpus[[1]])
corpus = tm_map(corpus, removeNumbers) # Eliminar numeros de las reviews del corpus
corpus = tm_map(corpus, removePunctuation) # Eliminar signos de puntuacion
corpus = tm_map(corpus, removeWords, stopwords(kind = 'en')) # Eliminar palabras irrelevantes
corpus = tm_map(corpus, stemDocument) # Eliminar las "variantes" de palabras por su "raiz" ej: loved -> love
corpus = tm_map(corpus, stripWhitespace) # Eliminar espacios en blanco
# Crear el modelo Bag of Words
dtm = DocumentTermMatrix(corpus)
dtm = removeSparseTerms(dtm, 0.999)
dataset = as.data.frame(as.matrix(dtm))
dataset$Liked = dataset_original$Liked
# Codificar la variable de clasificacion como factor
dataset$Liked = factor(dataset$Liked, levels = c(0, 1))
# Dividir los datos en conjunto de entrenamiento y conjunto de test
library(caTools) # Instalar con install.packages('caTools')
set.seed(123) # Para que salgan los mismos resultados que en el curso
split = sample.split(dataset$Liked, SplitRatio = 0.80)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Ajustar el clasificador de Random Forest con el conjunto de entrenamiento
library(randomForest) # Instalar con install.packages('randomForest')
classifier = randomForest(x = training_set[, -692],
y = training_set$Liked,
ntree = 10)
# Prediccion de los resultados con el conjunto de Testing
y_pred = predict(classifier, newdata = testing_set[, -692]) # Todo el dataset excluyendo la columna 3
# Crear la matriz de confusion
cm = table(testing_set[692], y_pred)
# Crear la matriz de confusion
.
cm = table(testing_set[, 692], y_pred)
cm
y_pred = predict(classifier, newdata = 'hello')
View(testing_set)
setwd("~/repos/machinelearning-az/datasets/Part 8 - Deep Learning")
setwd("~/repos/machinelearning-az/datasets/Part 8 - Deep Learning")
# Importar el dataset
dataset = read.csv('data/Churn_Modelling.csv')
View(dataset)
View(dataset)
dataset = dataset[, 4:14]
dataset$Geography = as.numeric(factor(dataset$Geography,
levels = c('France', 'Spain', 'Germany'),
labels = c(1, 2, 3)))
dataset$Gender = as.numeric(factor(dataset$Gender,
levels = c('Female', 'Male'),
labels = c(1, 2)))
View(dataset)
# Dividir los datos en conjunto de entrenamiento y conjunto de test
library(caTools) # Instalar con install.packages('caTools')
set.seed(123) # Para que salgan los mismos resultados que en el curso
split = sample.split(dataset$Exited, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
View(testing_set)
View(testing_set)
View(testing_set)
training_set[, -11] = scale(training_set[, -11])
testing_set[, -11] = scale(testing_set[, -11])
View(training_set)
install.packages('h2o')
# Crear la RNA
library(h2o) # Instalar con install.packages('h2o')
h2o.init(nthreads = -1)
classifier = h2o.deeplearning(y = 'Exited',
training_frame = training_set,
activation = 'Rectifier',
hidden = c(6, 6),
epochs = 100,
train_samples_per_iteration = -2)
classifier = h2o.deeplearning(y = 'Exited',
training_frame = as.h2o(training_set),
activation = 'Rectifier',
hidden = c(6, 6),
epochs = 100,
train_samples_per_iteration = -2)
# Redes Neuronales Artificiales
setwd("~/repos/machinelearning-az/datasets/Part 8 - Deep Learning")
# Importar el dataset
dataset = read.csv('data/Churn_Modelling.csv')
dataset = dataset[, 4:14]
# Codificar las variables Geography y Gender como factor
dataset$Geography = as.numeric(factor(dataset$Geography,
levels = c('France', 'Spain', 'Germany'),
labels = c(1, 2, 3)))
dataset$Gender = as.numeric(factor(dataset$Gender,
levels = c('Female', 'Male'),
labels = c(1, 2)))
# Dividir los datos en conjunto de entrenamiento y conjunto de test
library(caTools) # Instalar con install.packages('caTools')
set.seed(123) # Para que salgan los mismos resultados que en el curso
split = sample.split(dataset$Exited, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# Hay que indicar las columnas donde hacer el escalado
training_set[, -11] = scale(training_set[, -11])
testing_set[, -11] = scale(testing_set[, -11])
# Crear la RNA
library(h2o) # Instalar con install.packages('h2o')
h2o.init(nthreads = -1)
classifier = h2o.deeplearning(y = 'Exited',
training_frame = as.h2o(training_set),
activation = 'Rectifier',
hidden = c(6, 6),
epochs = 100,
train_samples_per_iteration = -2)
prob_pred = h2o.predict(classifier, newdata = testing_set[, -11]) # Todo el dataset excluyendo la columna 3
# Prediccion de los resultados con el conjunto de Testing
prob_pred = h2o.predict(classifier, newdata = as.h2o(testing_set[, -11])) # Todo el dataset excluyendo la columna 3
y_pred = ifelse(prob_pred > 0.5, 1, 0)
View(y_pred)
View(prob_pred)
prob_pred
y_pred
y_pred = as.vector(y_pred)
y_pred
cm = table(testing_set[, 11], y_pred)
# Redes Neuronales Artificiales
setwd("~/repos/machinelearning-az/datasets/Part 8 - Deep Learning")
# Importar el dataset
dataset = read.csv('data/Churn_Modelling.csv')
dataset = dataset[, 4:14]
# Codificar las variables Geography y Gender como factor
dataset$Geography = as.numeric(factor(dataset$Geography,
levels = c('France', 'Spain', 'Germany'),
labels = c(1, 2, 3)))
dataset$Gender = as.numeric(factor(dataset$Gender,
levels = c('Female', 'Male'),
labels = c(1, 2)))
# Dividir los datos en conjunto de entrenamiento y conjunto de test
library(caTools) # Instalar con install.packages('caTools')
set.seed(123) # Para que salgan los mismos resultados que en el curso
split = sample.split(dataset$Exited, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# Hay que indicar las columnas donde hacer el escalado
training_set[, -11] = scale(training_set[, -11])
testing_set[, -11] = scale(testing_set[, -11])
# Crear la RNA
library(h2o) # Instalar con install.packages('h2o')
h2o.init(nthreads = -1)
classifier = h2o.deeplearning(y = 'Exited',
training_frame = as.h2o(training_set),
activation = 'Rectifier',
hidden = c(6, 6),
epochs = 100,
train_samples_per_iteration = -2)
# Prediccion de los resultados con el conjunto de Testing
prob_pred = h2o.predict(classifier,
newdata = as.h2o(testing_set[, -11])) # Todo el dataset excluyendo la columna 11
y_pred = ifelse(prob_pred > 0.5, 1, 0)
y_pred = as.vector(y_pred)
# Crear la matriz de confusion
cm = table(testing_set[, 11], y_pred)
set.seed(123) # Para que salgan los mismos resultados que en el curso
split = sample.split(dataset$Exited, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# Hay que indicar las columnas donde hacer el escalado
training_set[, -11] = scale(training_set[, -11])
testing_set[, -11] = scale(testing_set[, -11])
# Crear la RNA
library(h2o) # Instalar con install.packages('h2o')
h2o.init(nthreads = -1)
classifier = h2o.deeplearning(y = 'Exited',
training_frame = as.h2o(training_set),
activation = 'Rectifier',
hidden = c(6, 6),
epochs = 100,
train_samples_per_iteration = -2)
# Prediccion de los resultados con el conjunto de Testing
prob_pred = h2o.predict(classifier,
newdata = as.h2o(testing_set[, -11])) # Todo el dataset excluyendo la columna 11
y_pred = ifelse(prob_pred > 0.5, 1, 0)
y_pred = as.vector(y_pred)
# Crear la matriz de confusion
cm = table(testing_set[, 11], y_pred)
# Redes Neuronales Artificiales
setwd("~/repos/machinelearning-az/datasets/Part 8 - Deep Learning")
# Importar el dataset
dataset = read.csv('data/Churn_Modelling.csv')
dataset = dataset[, 4:14]
# Codificar los factores para la RNA
dataset$Geography = as.numeric(factor(dataset$Geography,
levels = c("France", "Spain", "Germany"),
labels = c(1, 2, 3)))
dataset$Gender = as.numeric(factor(dataset$Gender,
levels = c("Female", "Male"),
labels = c(1,2)))
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
library(caTools)
set.seed(123)
split = sample.split(dataset$Exited, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de valores
training_set[,-11] = scale(training_set[,-11])
testing_set[,-11] = scale(testing_set[,-11])
# Crear la red Neuronal
#install.packages("h2o")
library(h2o)
h2o.init(nthreads = -1)
classifier = h2o.deeplearning(y = "Exited",
training_frame = as.h2o(training_set),
activation = "Rectifier",
hidden = c(6, 6),
epochs = 100,
train_samples_per_iteration = -2)
# Predicción de los resultados con el conjunto de testing
prob_pred = h2o.predict(classifier,
newdata = as.h2o(testing_set[,-11]))
y_pred = (prob_pred>0.5)
y_pred = as.vector(y_pred)
# Crear la matriz de confusión
cm = table(testing_set[, 11], y_pred)
prob_pred
# Redes Neuronales Artificiales
setwd("~/repos/machinelearning-az/datasets/Part 8 - Deep Learning")
# Importar el dataset
dataset = read.csv('data/Churn_Modelling.csv')
dataset = dataset[, 4:14]
# Codificar los factores para la RNA
dataset$Geography = as.numeric(factor(dataset$Geography,
levels = c("France", "Spain", "Germany"),
labels = c(1, 2, 3)))
dataset$Gender = as.numeric(factor(dataset$Gender,
levels = c("Female", "Male"),
labels = c(1,2)))
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
library(caTools)
set.seed(123)
split = sample.split(dataset$Exited, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de valores
training_set[,-11] = scale(training_set[,-11])
testing_set[,-11] = scale(testing_set[,-11])
# Crear la red Neuronal
#install.packages("h2o")
library(h2o)
h2o.init(nthreads = -1)
classifier = h2o.deeplearning(y = "Exited",
training_frame = as.h2o(training_set),
activation = "Rectifier",
hidden = c(6, 6),
epochs = 100,
train_samples_per_iteration = -2)
# Predicción de los resultados con el conjunto de testing
prob_pred = h2o.predict(classifier,
newdata = as.h2o(testing_set[,-11]))
y_pred = (prob_pred>0.5)
y_pred = as.vector(y_pred)
prob_pred
as.vector(prob_pred)
clear
cls
h2o.shutdown()
# Redes Neuronales Artificiales
setwd("~/repos/machinelearning-az/datasets/Part 8 - Deep Learning")
# Importar el dataset
dataset = read.csv('data/Churn_Modelling.csv')
dataset = dataset[, 4:14]
# Codificar las variables Geography y Gender como factor
dataset$Geography = as.numeric(factor(dataset$Geography,
levels = c('France', 'Spain', 'Germany'),
labels = c(1, 2, 3)))
dataset$Gender = as.numeric(factor(dataset$Gender,
levels = c('Female', 'Male'),
labels = c(1, 2)))
# Dividir los datos en conjunto de entrenamiento y conjunto de test
library(caTools) # Instalar con install.packages('caTools')
set.seed(123) # Para que salgan los mismos resultados que en el curso
split = sample.split(dataset$Exited, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# Hay que indicar las columnas donde hacer el escalado
training_set[, -11] = scale(training_set[, -11])
testing_set[, -11] = scale(testing_set[, -11])
# Crear la RNA
library(h2o) # Instalar con install.packages('h2o')
h2o.init(nthreads = -1)
classifier = h2o.deeplearning(y = 'Exited',
training_frame = as.h2o(training_set),
activation = 'Rectifier',
hidden = c(6, 6),
epochs = 100,
train_samples_per_iteration = -2)
# Prediccion de los resultados con el conjunto de Testing
prob_pred = h2o.predict(classifier,
newdata = as.h2o(testing_set[, -11])) # Todo el dataset excluyendo la columna 11
y_pred = prob_pred > 0.5
y_pred = as.vector(y_pred)
# Crear la matriz de confusion
cm = table(testing_set[, 11], y_pred)
y_pred
# Escalado de valores
# Hay que indicar las columnas donde hacer el escalado
training_set[, -11] = scale(training_set[, -11])
testing_set[, -11] = scale(testing_set[, -11])
# Crear la RNA
library(h2o) # Instalar con install.packages('h2o')
h2o.init(nthreads = -1)
classifier = h2o.deeplearning(y = 'Exited',
training_frame = as.h2o(training_set),
activation = 'Rectifier',
hidden = c(6, 6),
epochs = 100,
train_samples_per_iteration = -2)
# Prediccion de los resultados con el conjunto de Testing
prob_pred = h2o.predict(classifier,
newdata = as.h2o(testing_set[, -11])) # Todo el dataset excluyendo la columna 11
y_pred = prob_pred > 0.5
y_pred = as.vector(y_pred)
# Crear la matriz de confusion
cm = table(testing_set[, 11], y_pred)
classifier = h2o.deeplearning(y = 'Exited',
training_frame = as.h2o(training_set),
activation = 'Rectifier',
hidden = c(6, 6),
epochs = 100,
train_samples_per_iteration = -2)
# Prediccion de los resultados con el conjunto de Testing
prob_pred = h2o.predict(classifier,
newdata = as.h2o(testing_set[, -11])) # Todo el dataset excluyendo la columna 11
y_pred = prob_pred > 0.5
y_pred = as.vector(y_pred)
# Crear la matriz de confusion
cm = table(testing_set[, 11], y_pred)
prob_pred
# Redes Neuronales Artificiales
setwd("~/repos/machinelearning-az/datasets/Part 8 - Deep Learning")
# Importar el dataset
dataset = read.csv('data/Churn_Modelling.csv')
dataset = dataset[, 4:14]
# Codificar los factores para la RNA
dataset$Geography = as.numeric(factor(dataset$Geography,
levels = c("France", "Spain", "Germany"),
labels = c(1, 2, 3)))
dataset$Gender = as.numeric(factor(dataset$Gender,
levels = c("Female", "Male"),
labels = c(1,2)))
# Dividir los datos en conjunto de entrenamiento y conjunto de test
# install.packages("caTools")
library(caTools)
set.seed(123)
split = sample.split(dataset$Exited, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de valores
training_set[,-11] = scale(training_set[,-11])
testing_set[,-11] = scale(testing_set[,-11])
# Crear la red Neuronal
#install.packages("h2o")
library(h2o)
h2o.init(nthreads = -1)
classifier = h2o.deeplearning(y = "Exited",
training_frame = as.h2o(training_set),
activation = "Rectifier",
hidden = c(6, 6),
epochs = 100,
train_samples_per_iteration = -2)
# Predicción de los resultados con el conjunto de testing
prob_pred = h2o.predict(classifier,
newdata = as.h2o(testing_set[,-11]))
y_pred = (prob_pred>0.5)
y_pred = as.vector(y_pred)
# Crear la matriz de confusión
cm = table(testing_set[, 11], y_pred)
prob_pred
h2o.shutdown()
# Redes Neuronales Artificiales
setwd("~/repos/machinelearning-az/datasets/Part 8 - Deep Learning")
# Importar el dataset
dataset = read.csv('data/Churn_Modelling.csv')
dataset = dataset[, 4:14]
# Codificar las variables Geography y Gender como factor
dataset$Geography = as.numeric(factor(dataset$Geography,
levels = c('France', 'Spain', 'Germany'),
labels = c(1, 2, 3)))
dataset$Gender = as.numeric(factor(dataset$Gender,
levels = c('Female', 'Male'),
labels = c(1, 2)))
# Dividir los datos en conjunto de entrenamiento y conjunto de test
library(caTools) # Instalar con install.packages('caTools')
set.seed(123) # Para que salgan los mismos resultados que en el curso
split = sample.split(dataset$Exited, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# Hay que indicar las columnas donde hacer el escalado
training_set[, -11] = scale(training_set[, -11])
testing_set[, -11] = scale(testing_set[, -11])
# Crear la RNA
library(h2o) # Instalar con install.packages('h2o')
h2o.init(nthreads = -1)
classifier = h2o.deeplearning(y = 'Exited',
training_frame = as.h2o(training_set),
activation = 'Rectifier',
hidden = c(6, 6),
epochs = 100,
train_samples_per_iteration = -2)
# Prediccion de los resultados con el conjunto de Testing
prob_pred = h2o.predict(classifier,
newdata = as.h2o(testing_set[, -11])) # Todo el dataset excluyendo la columna 11
y_pred = prob_pred > 0.5
y_pred = as.vector(y_pred)
# Crear la matriz de confusion
cm = table(testing_set[, 11], y_pred)
# Cerrar la sesion de H2O
h2o.shutdown()
prob_pred
View(testing_set)
# Redes Neuronales Artificiales
setwd("~/repos/machinelearning-az/datasets/Part 8 - Deep Learning")
# Importar el dataset
dataset = read.csv('data/Churn_Modelling.csv')
dataset = dataset[, 4:14]
# Codificar las variables Geography y Gender como factor
dataset$Geography = as.numeric(factor(dataset$Geography,
levels = c('France', 'Spain', 'Germany'),
labels = c(1, 2, 3)))
dataset$Gender = as.numeric(factor(dataset$Gender,
levels = c('Female', 'Male'),
labels = c(1, 2)))
# Dividir los datos en conjunto de entrenamiento y conjunto de test
library(caTools) # Instalar con install.packages('caTools')
set.seed(123) # Para que salgan los mismos resultados que en el curso
split = sample.split(dataset$Exited, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# Hay que indicar las columnas donde hacer el escalado
training_set[, -11] = scale(training_set[, -11])
testing_set[, -11] = scale(testing_set[, -11])
# Crear la RNA
library(h2o) # Instalar con install.packages('h2o')
h2o.init(nthreads = -1)
classifier = h2o.deeplearning(y = 'Exited',
training_frame = as.h2o(training_set),
activation = 'Rectifier',
hidden = c(6, 6),
epochs = 100,
train_samples_per_iteration = -2)
# Prediccion de los resultados con el conjunto de Testing
prob_pred = h2o.predict(classifier,
newdata = as.h2o(testing_set[, -11])) # Todo el dataset excluyendo la columna 11
y_pred = prob_pred > 0.5
y_pred = as.vector(y_pred)
# Crear la matriz de confusion
cm = table(testing_set[, 11], y_pred)
# Cerrar la sesion de H2O
h2o.shutdown()
prob_pred
prob_pred
