# Crear la matriz de confusion
cm = table(testing_set[, 3], y_pred)
# Visualizacion del conjunto de Entrenamiento
# Con install.packages('ElemStatLearn')
library(ElemStatLearn)
# Visualizacion del conjunto de Entrenamiento
# Con install.packages('ElemStatLearn')
library(ElemStatLearn)
setwd("~/repos/machinelearning-az/datasets/Part 3 - Classification")
# Importar el dataset
dataset = read.csv('data/Social_Network_Ads.csv')
dataset = dataset[, 3:5]
# Codificar la variable de clasificacion como factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Dividir los datos en conjunto de entrenamiento y conjunto de test
library(caTools) # Instalar con install.packages('caTools')
set.seed(123) # Para que salgan los mismos resultados que en el curso
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Ajustar el clasificador con el conjunto de entrenamiento
library(rpart) # Instalar con install.packages('rpart')
classifier = rpart(formula = Purchased ~.,
data = training_set)
# Prediccion de los resultados con el conjunto de Testing
y_pred = predict(classifier, newdata = testing_set[, -3],
type = 'class') # Todo el dataset excluyendo la columna 3
# Crear la matriz de confusion
cm = table(testing_set[, 3], y_pred)
# Visualizacion del conjunto de Entrenamiento
# Con install.packages('ElemStatLearn')
library(ElemStatLearn)
install.packages('ElemStatLearn')
# Visualizacion del conjunto de Entrenamiento
# Con install.packages('ElemStatLearn')
library(ElemStatLearn)
install.packages("C:/Users/mudar/Downloads/ElemStatLearn_2015.6.26.2.tar.gz", repos = NULL, type = "source")
# Visualizacion del conjunto de Entrenamiento
# Con install.packages('ElemStatLearn') salta error
# Entrar en https://cran.r-project.org/src/contrib/Archive/ElemStatLearn/
# Descargar e instalar version ElemStatLearn_2015.6.26.2.tar.gz
library(ElemStatLearn)
setwd("~/repos/machinelearning-az/datasets/Part 3 - Classification")
# Importar el dataset
dataset = read.csv('data/Social_Network_Ads.csv')
dataset = dataset[, 3:5]
# Dividir los datos en conjunto de entrenamiento y conjunto de test
library(caTools) # Instalar con install.packages('caTools')
set.seed(123) # Para que salgan los mismos resultados que en el curso
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# Hay que indicar las columnas donde hacer el escalado
training_set[, 1:2] = scale(training_set[, 1:2])
testing_set[, 1:2] = scale(testing_set[, 1:2])
# Ajustar el SVM con el conjunto de entrenamiento
library(e1071) # Instalar con install.packages('e1071')
classifier = svm(formula = Purchased ~ .,
data = training_set,
type = 'C-classification',
kernel = 'linear')
# Prediccion de los resultados con el conjunto de Testing
y_pred = predict(classifier, newdata = testing_set[, -3]) # Todo el dataset excluyendo la columna 3
# Crear la matriz de confusion
cm = table(testing_set[, 3], y_pred)
# Visualizacion del conjunto de Entrenamiento
# Con install.packages('ElemStatLearn') salta error
# Entrar en https://cran.r-project.org/src/contrib/Archive/ElemStatLearn/
# Descargar e instalar version ElemStatLearn_2015.6.26.2.tar.gz
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.1)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.1)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'SVM (Conjunto de Entrenamiento)',
xlab = 'Edad', ylab = 'Sueldo Estimado',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'SVM (Conjunto de Entrenamiento)',
xlab = 'Edad', ylab = 'Sueldo Estimado',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
setwd("~/repos/machinelearning-az/datasets/Part 3 - Classification")
# Importar el dataset
dataset = read.csv('data/Social_Network_Ads.csv')
dataset = dataset[, 3:5]
# Dividir los datos en conjunto de entrenamiento y conjunto de test
library(caTools) # Instalar con install.packages('caTools')
set.seed(123) # Para que salgan los mismos resultados que en el curso
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# Hay que indicar las columnas donde hacer el escalado
training_set[, 1:2] = scale(training_set[, 1:2])
testing_set[, 1:2] = scale(testing_set[, 1:2])
# Ajustar el clasificador con el conjunto de entrenamiento
library(e1071) # Instalar con install.packages('e1071')
classifier = svm(formula = Purchased ~ .,
data = training_set,
type = 'C-classification',
kernel = 'radial')
# Prediccion de los resultados con el conjunto de Testing
y_pred = predict(classifier, newdata = testing_set[, -3]) # Todo el dataset excluyendo la columna 3
# Crear la matriz de confusion
cm = table(testing_set[, 3], y_pred)
# Visualizacion del conjunto de Entrenamiento
# Con install.packages('ElemStatLearn') salta error
# Entrar en https://cran.r-project.org/src/contrib/Archive/ElemStatLearn/
# Descargar e instalar version ElemStatLearn_2015.6.26.2.tar.gz
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'SVM Kernel (Conjunto de Entrenamiento)',
xlab = 'Edad', ylab = 'Sueldo Estimado',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
setwd("~/repos/machinelearning-az/datasets/Part 3 - Classification")
# Importar el dataset
dataset = read.csv('data/Social_Network_Ads.csv')
dataset = dataset[, 3:5]
# Dividir los datos en conjunto de entrenamiento y conjunto de test
library(caTools) # Instalar con install.packages('caTools')
set.seed(123) # Para que salgan los mismos resultados que en el curso
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# Hay que indicar las columnas donde hacer el escalado
training_set[, 1:2] = scale(training_set[, 1:2])
testing_set[, 1:2] = scale(testing_set[, 1:2])
# Ajustar el K-NN con el conjunto de entrenamiento
# y hacer las predicciones con el conjunto de testing
library(class) # Instalar con install.packages('class')
y_pred = knn(train = training_set[, -3],
test = testing_set[, -3],
cl = training_set[, 3],
k = 5)
# Crear la matriz de confusion
cm = table(testing_set[, 3], y_pred)
# Visualizacion del conjunto de Entrenamiento
# Con install.packages('ElemStatLearn') salta error
# Entrar en https://cran.r-project.org/src/contrib/Archive/ElemStatLearn/
# Descargar e instalar version ElemStatLearn_2015.6.26.2.tar.gz
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = knn(train = training_set[, -3],
test = grid_set,
cl = training_set[, 3],
k = 5)
plot(set[, -3],
main = 'K-NN (Conjunto de Entrenamiento)',
xlab = 'Edad', ylab = 'Sueldo Estimado',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
setwd("~/repos/machinelearning-az/datasets/Part 3 - Classification")
# Importar el dataset
dataset = read.csv('data/Social_Network_Ads.csv')
dataset = dataset[, 3:5]
# Dividir los datos en conjunto de entrenamiento y conjunto de test
library(caTools) # Instalar con install.packages('caTools')
set.seed(123) # Para que salgan los mismos resultados que en el curso
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# Hay que indicar las columnas donde hacer el escalado
training_set[, 1:2] = scale(training_set[, 1:2])
testing_set[, 1:2] = scale(testing_set[, 1:2])
# Ajustar el modelo de Regresion Logistica con el conjunto de entrenamiento
classifier = glm(formula = Purchased ~ .,
data = training_set,
family = binomial)
# Prediccion de los resultados con el conjunto de Testing
prob_pred = predict(classifier, type = 'response',
newdata = testing_set[, -3]) # Todo el dataset excluyendo la columna 3
y_pred = ifelse(prob_pred > 0.5, 1, 0)
# Crear la matriz de confusion
cm = table(testing_set[, 3], y_pred)
# Visualizacion del conjunto de Entrenamiento
# Con install.packages('ElemStatLearn') salta error
# Entrar en https://cran.r-project.org/src/contrib/Archive/ElemStatLearn/
# Descargar e instalar version ElemStatLearn_2015.6.26.2.tar.gz
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Clasificación (Conjunto de Entrenamiento)',
xlab = 'Edad', ylab = 'Sueldo Estimado',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
install.packages('caTools')
install.packages("caTools")
install.packages('caTools')
setwd("~/repos/machinelearning-az/datasets/Part 3 - Classification")
# Importar el dataset
dataset = read.csv('data/Social_Network_Ads.csv')
dataset = dataset[, 3:5]
# Codificar la variable de clasificacion como factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Dividir los datos en conjunto de entrenamiento y conjunto de test
library(caTools) # Instalar con install.packages('caTools')
set.seed(123) # Para que salgan los mismos resultados que en el curso
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# Hay que indicar las columnas donde hacer el escalado
training_set[, 1:2] = scale(training_set[, 1:2])
testing_set[, 1:2] = scale(testing_set[, 1:2])
# Ajustar el clasificador con el conjunto de entrenamiento
library(e1071) # Instalar con install.packages('e1071')
classifier = naiveBayes(x = training_set[, -3],
y = training_set$Purchased)
# Prediccion de los resultados con el conjunto de Testing
y_pred = predict(classifier, newdata = testing_set[, -3]) # Todo el dataset excluyendo la columna 3
# Crear la matriz de confusion
cm = table(testing_set[, 3], y_pred)
# Visualizacion del conjunto de Entrenamiento
# Con install.packages('ElemStatLearn') salta error
# Entrar en https://cran.r-project.org/src/contrib/Archive/ElemStatLearn/
# Descargar e instalar version ElemStatLearn_2015.6.26.2.tar.gz
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'Naïve Bayes (Conjunto de Entrenamiento)',
xlab = 'Edad', ylab = 'Sueldo Estimado',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
setwd("~/repos/machinelearning-az/datasets/Part 3 - Classification")
# Importar el dataset
dataset = read.csv('data/Social_Network_Ads.csv')
dataset = dataset[, 3:5]
# Codificar la variable de clasificacion como factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Dividir los datos en conjunto de entrenamiento y conjunto de test
library(caTools) # Instalar con install.packages('caTools')
set.seed(123) # Para que salgan los mismos resultados que en el curso
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
testing_set = subset(dataset, split == FALSE)
# Escalado de valores
# Hay que indicar las columnas donde hacer el escalado
training_set[, 1:2] = scale(training_set[, 1:2])
testing_set[, 1:2] = scale(testing_set[, 1:2])
# Ajustar el clasificador de Random Forest con el conjunto de entrenamiento
library(randomForest) # Instalar con install.packages('randomForest')
classifier = randomForest(x = training_set[, -3],
y = training_set[, 3],
ntree = 10)
# Prediccion de los resultados con el conjunto de Testing
y_pred = predict(classifier, newdata = testing_set[, -3]) # Todo el dataset excluyendo la columna 3
# Crear la matriz de confusion
cm = table(testing_set[, 3], y_pred)
# Visualizacion del conjunto de Entrenamiento
# Con install.packages('ElemStatLearn') salta error
# Entrar en https://cran.r-project.org/src/contrib/Archive/ElemStatLearn/
# Descargar e instalar version ElemStatLearn_2015.6.26.2.tar.gz
library(ElemStatLearn)
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'Random Forest (Conjunto de Entrenamiento)',
xlab = 'Edad', ylab = 'Sueldo Estimado',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'Random Forest (Conjunto de Entrenamiento)',
xlab = 'Edad', ylab = 'Sueldo Estimado',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
setwd("~/repos/machinelearning-az/datasets/Part 5 - Association Rule Learning")
# Importar los datos
dataset = read.csv('data/Market_Basket_Optimisation.csv', header = FALSE)
library(arules) # Instalar con install.packages('arules')
dataset = read.transactions('data/Market_Basket_Optimisation.csv',
sep = ',')
setwd("~/repos/machinelearning-az/datasets/Part 5 - Association Rule Learning")
# Importar los datos
library(arules) # Instalar con install.packages('arules')
dataset = read.csv('data/Market_Basket_Optimisation.csv', header = FALSE)
dataset = read.transactions('data/Market_Basket_Optimisation.csv',
sep = ',')
setwd("~/repos/machinelearning-az/datasets/Part 5 - Association Rule Learning")
# Importar los datos
library(arules) # Instalar con install.packages('arules')
dataset = read.csv('data/Market_Basket_Optimisation.csv', header = FALSE)
dataset = read.transactions('data/Market_Basket_Optimisation.csv',
sep = ',')
View(dataset)
setwd("~/repos/machinelearning-az/datasets/Part 5 - Association Rule Learning")
# Importar los datos
library(arules) # Instalar con install.packages('arules')
dataset = read.csv('data/Market_Basket_Optimisation.csv', header = FALSE)
dataset = read.transactions('data/Market_Basket_Optimisation.csv',
sep = ',', rm.duplicates = TRUE)
summary(dataset)
itemFrequencyPlot(dataset)
itemFrequencyPlot(dataset, topN = 100)
itemFrequencyPlot(dataset, topN = 10)
# Apriori
setwd("~/repos/machinelearning-az/datasets/Part 5 - Association Rule Learning")
# Importar los datos
library(arules) # Instalar con install.packages('arules')
dataset = read.csv('data/Market_Basket_Optimisation.csv', header = FALSE)
dataset = read.transactions('data/Market_Basket_Optimisation.csv',
sep = ',', rm.duplicates = TRUE)
summary(dataset)
itemFrequencyPlot(dataset, topN = 10)
3*7/7500
# Entrenar algoritmo Apriori con el dataset
rules = apriori(data = dataset,
parameter = list(support = 0.003, confidence = 0.8))
rules = apriori(data = dataset,
parameter = list(support = 0.003, confidence = 0.4))
# Visualizacion de los resultados
inspect(rules[1:10])
# Visualizacion de los resultados
inspect(sort(rules, by = 'lift')[1:10])
install.packages('arulesViz')
# libraries --------------------------------------------------------------
library(arules)
library(arulesViz)
# data -------------------------------------------------------------------
path <- "~/repos/machinelearning-az/datasets/Part 5 - Association Rule Learning"
trans <- read.transactions(
file = paste0(path, "data/Market_Basket_Optimisation.csv"),
sep = ",",
rm.duplicates = TRUE
)
# data -------------------------------------------------------------------
path <- "~/repos/machinelearning-az/datasets/Part 5 - Association Rule Learning"
trans <- read.transactions(
file = paste0(path, "/data/Market_Basket_Optimisation.csv"),
sep = ",",
rm.duplicates = TRUE
)
# apriori algoirthm ------------------------------------------------------
rules <- apriori(
data = trans,
parameter = list(support = 0.004, confidence = 0.2)
)
# visualizations ---------------------------------------------------------
plot(rules, method = "graph", engine = "htmlwidget")
# libraries --------------------------------------------------------------
library(arules)
library(arulesViz)
# data -------------------------------------------------------------------
path <- "~/repos/machinelearning-az/datasets/Part 5 - Association Rule Learning/"
trans <- read.transactions(
file = paste0(path, "data/Market_Basket_Optimisation.csv"),
sep = ",",
rm.duplicates = TRUE
)
# apriori algoirthm ------------------------------------------------------
rules <- apriori(
data = trans,
parameter = list(support = 0.004, confidence = 0.2)
)
# visualizations ---------------------------------------------------------
plot(rules, method = "graph", engine = "htmlwidget")
# Entrenar algoritmo Apriori con el dataset
rules = apriori(data = dataset,
parameter = list(support = 0.004, confidence = 0.2))
# Visualizacion de los resultados
inspect(sort(rules, by = 'lift')[1:10])
setwd("~/repos/machinelearning-az/datasets/Part 5 - Association Rule Learning")
# Importar los datos
library(arules) # Instalar con install.packages('arules')
dataset = read.csv('data/Market_Basket_Optimisation.csv', header = FALSE)
dataset = read.transactions('data/Market_Basket_Optimisation.csv',
sep = ',', rm.duplicates = TRUE)
summary(dataset)
itemFrequencyPlot(dataset, topN = 10)
# Entrenar algoritmo Apriori con el dataset
rules = apriori(data = dataset,
parameter = list(support = 0.004, confidence = 0.2))
# Visualizacion de los resultados
inspect(sort(rules, by = 'lift')[1:10])
library(arulesViz)
# visualizations ---------------------------------------------------------
plot(rules, method = "graph", engine = "htmlwidget")
detach("package:arulesViz", unload = TRUE)
s
setwd("~/repos/machinelearning-az/datasets/Part 5 - Association Rule Learning")
# Importar los datos
library(arules) # Instalar con install.packages('arules')
dataset = read.csv('data/Market_Basket_Optimisation.csv', header = FALSE)
dataset = read.transactions('data/Market_Basket_Optimisation.csv',
sep = ',', rm.duplicates = TRUE)
summary(dataset)
itemFrequencyPlot(dataset, topN = 10)
# Entrenar algoritmo Apriori con el dataset
rules = apriori(data = dataset,
parameter = list(support = 0.004, confidence = 0.2))
# Visualizacion de los resultados
inspect(sort(rules, by = 'lift')[1:10])
# Representacion grafica de las regla s de asociacion
#library(arulesViz)
plot(rules, method = "graph", engine = "htmlwidget")
# Apriori
setwd("~/repos/machinelearning-az/datasets/Part 5 - Association Rule Learning")
# Importar los datos
library(arules) # Instalar con install.packages('arules')
dataset = read.csv('data/Market_Basket_Optimisation.csv', header = FALSE)
dataset = read.transactions('data/Market_Basket_Optimisation.csv',
sep = ',', rm.duplicates = TRUE)
summary(dataset)
itemFrequencyPlot(dataset, topN = 10)
# Entrenar algoritmo Apriori con el dataset
rules = apriori(data = dataset,
parameter = list(support = 0.004, confidence = 0.2))
# Visualizacion de los resultados
inspect(sort(rules, by = 'lift')[1:10])
# Representacion grafica de las regla s de asociacion
#library(arulesViz)
plot(rules, method = "graph", engine = "htmlwidget")
# Representacion grafica de las regla s de asociacion
library(arulesViz)
plot(rules, method = "graph", engine = "htmlwidget")
dataset = read.transactions('data/Market_Basket_Optimisation.csv',
sep = ',', rm.duplicates = TRUE)
summary(dataset)
View(dataset)
itemFrequencyPlot(dataset, topN = 100)
# Entrenar algoritmo Eclat con el dataset
rules = eclat(data = dataset,
parameter = list(support = 0.004, confidence = 0.2))
# Entrenar algoritmo Eclat con el dataset
rules = eclat(data = dataset,
parameter = list(support = 0.004))
# Visualizacion de los resultados
inspect(sort(rules, by = 'lift')[1:10])
library(arulesViz)
plot(rules, method = "graph", engine = "htmlwidget")
# Entrenar algoritmo Eclat con el dataset
rules = eclat(data = dataset,
parameter = list(support = 0.004, minlen = 2))
plot(rules, method = "graph", engine = "htmlwidget")
# Visualizacion de los resultados
inspect(sort(rules, by = 'support')[1:10])
setwd("~/repos/machinelearning-az/datasets/Part 5 - Association Rule Learning")
# Importar los datos
library(arules) # Instalar con install.packages('arules')
dataset = read.csv('data/Market_Basket_Optimisation.csv', header = FALSE)
dataset = read.transactions('data/Market_Basket_Optimisation.csv',
sep = ',', rm.duplicates = TRUE)
summary(dataset)
itemFrequencyPlot(dataset, topN = 100)
# Entrenar algoritmo Apriori con el dataset
rules = apriori(data = dataset,
parameter = list(support = 0.004, confidence = 0.2))
# Visualizacion de los resultados
inspect(sort(rules, by = 'lift')[1:10])
# Representacion grafica de las reglas de asociacion
library(arulesViz)
plot(rules, method = "graph", engine = "htmlwidget")
